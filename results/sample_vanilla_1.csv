Paper,Conference,Citation Number,Authors,Number of Authors,Title,Publication Year,Publication Venue,Id,Title_sch,Venue_sch,Publication Venue_sch,Publication Year_sch,Authors_sch,Number Authors_sch,Citation Count_sch,Influential Citation Count_sch,Reference Count_sch,Open Access_sch,Field of Study_sch,Field of Study s2_sch,In Paper,In Intro,Not Found,Score title,Score author,Exists,identifier,Title Length,Title Length_sch,Publication Venue_processed,Venue_sch_processed,strategy,Unique,order
Efficient Aggregated Kernel Tests using Incomplete $U$-statistics,NeurIPS,20,"Jitkrittum, W., Gretton, A., Borgwardt, K., Peebles, D., Al Efishat, M., & Szabó, Z.",6.0,Kernel-Based Just-In-Time Learning for Passing Expectation Propagation Messages,2019.0,Uncertainty in Artificial Intelligence (UAI),856d6317a884cb93ea35204dfbf041d20e98ec58,Kernel-Based Just-In-Time Learning for Passing Expectation Propagation Messages,Conference on Uncertainty in Artificial Intelligence,Conference on Uncertainty in Artificial Intelligence,2015.0,"Wittawat Jitkrittum, A. Gretton, N. Heess, S. Eslami, Balaji Lakshminarayanan, D. Sejdinovic, Z. Szabó",7.0,31.0,4.0,33.0,False,"['Mathematics', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,62.0,1.0,Efficient Aggregated Kernel Tests using Incomplete $U$-statistics20,79.0,79.0,Uncertainty in Artificial Intelligence (UAI),Conference on Uncertainty in Artificial Intelligence,vanilla_1,1,Efficient Aggregated Kernel Tests using Incomplete $U$-statistics20vanilla_1
Mirror Descent Maximizes Generalized Margin and Can Be Implemented Efficiently,NeurIPS,2,"Zhang, H., Mhammedi, Z., Durrant, R.J.",3.0,Convergence Analysis of Mirror Descent Methods,2018.0,Proceedings of the 35th International Conference on Machine Learning,,,,,,,,,,,,,,,,,63.0,39.0,0.0,Mirror Descent Maximizes Generalized Margin and Can Be Implemented Efficiently2,46.0,,ICML,,vanilla_1,0,Mirror Descent Maximizes Generalized Margin and Can Be Implemented Efficiently2vanilla_1
A Quadrature Rule combining Control Variates and Adaptive Importance Sampling,NeurIPS,16,"Shmueli, G.",1.0,Kernel-based importance sampling,2005.0,Proceedings of the American Statistical Association,,,,,,,,,,,,,,,,,84.0,20.0,0.0,A Quadrature Rule combining Control Variates and Adaptive Importance Sampling16,32.0,,Proceedings of the American Statistical Association,,vanilla_1,0,A Quadrature Rule combining Control Variates and Adaptive Importance Sampling16vanilla_1
Maximum Common Subgraph Guided Graph Retrieval: Late and Early Interaction Networks,NeurIPS,32,"Ling H., Jacobs, D.W.",2.0,Shape classification using the inner-distance,2007.0,IEEE Transactions on Pattern Analysis and Machine Intelligence,c9bb27a60b6c2555a4c01c4c0b8808f1e3625403,Shape Classification Using the Inner-Distance,IEEE Transactions on Pattern Analysis and Machine Intelligence,IEEE Transactions on Pattern Analysis and Machine Intelligence,2007.0,"Haibin Ling, D. Jacobs",2.0,1151.0,236.0,53.0,True,"['Mathematics', 'Medicine', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,87.0,1.0,Maximum Common Subgraph Guided Graph Retrieval: Late and Early Interaction Networks32,45.0,45.0,IEEE Transactions on Pattern Analysis and Machine Intelligence,IEEE Transactions on Pattern Analysis and Machine Intelligence,vanilla_1,0,Maximum Common Subgraph Guided Graph Retrieval: Late and Early Interaction Networks32vanilla_1
AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation,ICML,9,"Volpi, R., Morerio, P., Savarese, S., & Murino, V.",4.0,Adversarial Feature Augmentation for Unsupervised Domain Adaptation,2018.0,CVPR,42563d601d30bb74a15855ef912692e45c72340e,Adversarial Feature Augmentation for Unsupervised Domain Adaptation,2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition,,2017.0,"Riccardo Volpi, Pietro Morerio, S. Savarese, Vittorio Murino",4.0,210.0,16.0,44.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,91.0,1.0,AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation9,67.0,67.0,CVPR,CVPR,vanilla_1,1,AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation9vanilla_1
Approximately Optimal Core Shapes for Tensor Decompositions,ICML,34,"Albrecht, S., & Rauhut, H.",2.0,Randomized algorithms for low-rank tensor completion,2018.0,Information and Inference: A Journal of the IMA,,,,,,,,,,,,,,,,,42.0,30.0,0.0,Approximately Optimal Core Shapes for Tensor Decompositions34,52.0,,Information and Inference: A Journal of the IMA,,vanilla_1,0,Approximately Optimal Core Shapes for Tensor Decompositions34vanilla_1
How to prepare your task head for finetuning,ICLR,6,"Nakkiran, P., Kaplun, G., Bansal, Y., Yang, T., Barak, B., Sutskever, I.",6.0,Deep double descent: Where bigger models and more data hurt,2020.0,arXiv preprint arXiv:1912.02292,ea415809bf87ef4b99966c6c50de6cb996a02a97,Deep double descent: where bigger models and more data hurt,International Conference on Learning Representations,International Conference on Learning Representations,2019.0,"Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, B. Barak, Ilya Sutskever",6.0,672.0,86.0,50.0,True,"['Computer Science', 'Mathematics', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,90.0,1.0,How to prepare your task head for finetuning6,59.0,59.0,arxiv,ICLR,vanilla_1,1,How to prepare your task head for finetuning6vanilla_1
The Unsurprising Effectiveness of Pre-Trained Vision Models for Control,ICML,13,"Gu, S., Lillicrap, T., Sutskever, I., Levine, S.",4.0,Continuous deep Q-learning with model-based acceleration,2016.0,International Conference on Machine Learning,d358d41c69450b171327ebd99462b6afef687269,Continuous Deep Q-Learning with Model-based Acceleration,International Conference on Machine Learning,International Conference on Machine Learning,2016.0,"S. Gu, T. Lillicrap, Ilya Sutskever, S. Levine",4.0,889.0,86.0,41.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,97.0,1.0,The Unsurprising Effectiveness of Pre-Trained Vision Models for Control13,56.0,56.0,ICML,ICML,vanilla_1,0,The Unsurprising Effectiveness of Pre-Trained Vision Models for Control13vanilla_1
Continual Vision-Language Representation Learning with Off-Diagonal Information,ICML,10,"McCloskey, Michael, And Neal J. Cohen.",2.0,Catastrophic Interference In Connectionist Networks: The Sequential Learning Problem.,1989.0,"Psychology of learning and motivation, Vol. 24",c213af6582c0d518a6e8e14217611c733eeb1ef1,Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem,,,1989.0,"M. McCloskey, N. J. Cohen",2.0,3098.0,91.0,15.0,False,"['Computer Science', 'Psychology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,89.0,1.0,Continual Vision-Language Representation Learning with Off-Diagonal Information10,85.0,84.0,"Psychology of learning and motivation, Vol. 24",,vanilla_1,0,Continual Vision-Language Representation Learning with Off-Diagonal Information10vanilla_1
Curriculum Reinforcement Learning using Optimal Transport via Gradual Domain Adaptation,NeurIPS,4,"Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G.,... & Dieleman, S.",8.0,Mastering the game of Go with deep neural networks and tree search,2016.0,Nature,846aedd869a00c09b40f1f1f35673cb22bc87490,Mastering the game of Go with deep neural networks and tree search,Nature,Nature,2016.0,"David Silver, Aja Huang, Chris J. Maddison, A. Guez, L. Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Vedavyas Panneershelvam, Marc Lanctot, S. Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, D. Hassabis",20.0,14365.0,507.0,72.0,True,"['Medicine', 'Computer Science']","[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,67.0,1.0,Curriculum Reinforcement Learning using Optimal Transport via Gradual Domain Adaptation4,66.0,66.0,Nature,Nature,vanilla_1,1,Curriculum Reinforcement Learning using Optimal Transport via Gradual Domain Adaptation4vanilla_1
"Hypergraph Modeling via Spectral Embedding Connection: Hypergraph Cut, Weighted Kernel $k$-means, and Heat Kernel",AAAI,10,"Qi, Guangda; Aggarwal, Charu; Han, Jiawei; Huang, Thomas",4.0,Mining Collective Intelligence in Diverse Groups.,2013.0,Proceedings of the 22nd International Conference on World Wide Web,fc11136a4b239e5cef57aff29bc3a90448269d52,Mining collective intelligence in diverse groups,The Web Conference,The Web Conference,2013.0,"Guo-Jun Qi, C. Aggarwal, Jiawei Han, Thomas S. Huang",4.0,95.0,6.0,20.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,85.0,1.0,"Hypergraph Modeling via Spectral Embedding Connection: Hypergraph Cut, Weighted Kernel $k$-means, and Heat Kernel10",49.0,48.0,Proceedings of the 22nd International Conference on World Wide Web,The Web Conference,vanilla_1,0,"Hypergraph Modeling via Spectral Embedding Connection: Hypergraph Cut, Weighted Kernel $k$-means, and Heat Kernel10vanilla_1"
RenyiCL: Contrastive Representation Learning with Skew Renyi Divergence,NeurIPS,17,Yingzhen Li and Richard E. Turner,2.0,Rényi Divergence Variational Inference,2016.0,Advances in Neural Information Processing Systems 29,803f5fc50765fa2ac1c72659dca02f285fa48d4b,Rényi Divergence Variational Inference,Neural Information Processing Systems,Neural Information Processing Systems,2016.0,"Yingzhen Li, Richard E. Turner",2.0,226.0,32.0,31.0,False,"['Mathematics', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",1.0,0.0,0.0,100.0,100.0,1.0,RenyiCL: Contrastive Representation Learning with Skew Renyi Divergence17,38.0,38.0,NeurIPS,NeurIPS,vanilla_1,1,RenyiCL: Contrastive Representation Learning with Skew Renyi Divergence17vanilla_1
TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs,AAAI,24,"Yang, Y., Zhai, R., Zhang, C., & Zhang, J.",4.0,TAGGEN: Learning to Generate Task-Based Adventure Games,2018.0,ICCC,,,,,,,,,,,,,,,,,46.0,28.0,0.0,TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs24,55.0,,ICCC,,vanilla_1,1,TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs24vanilla_1
"Understanding, Predicting and Better Resolving Q-Value Divergence in Offline-RL",NeurIPS,2,"Sutton, R. S., & Barto, A. G.",2.0,Introduction to reinforcement learning,2012.0,MIT press,382f2d3c7e318c3ad2de028c6598a9700899ce80,Introduction to Reinforcement Learning,,,1998.0,"Richard S. Sutton, A. Barto",2.0,2714.0,69.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,89.0,1.0,"Understanding, Predicting and Better Resolving Q-Value Divergence in Offline-RL2",38.0,38.0,MIT press,,vanilla_1,0,"Understanding, Predicting and Better Resolving Q-Value Divergence in Offline-RL2vanilla_1"
Self-Correcting Bayesian Optimization through Bayesian Active Learning,NeurIPS,60,"Wang, Z., & Jegelka, S.",2.0,Max-value entropy search for efficient Bayesian optimization,2017.0,Proceedings of the 34th International Conference on Machine Learning,0d03c970454f55fc3627c340e92a1de55220a304,Max-value Entropy Search for Efficient Bayesian Optimization,International Conference on Machine Learning,International Conference on Machine Learning,2017.0,"Zi Wang, S. Jegelka",2.0,325.0,62.0,41.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",1.0,0.0,0.0,100.0,97.0,1.0,Self-Correcting Bayesian Optimization through Bayesian Active Learning60,60.0,60.0,ICML,ICML,vanilla_1,0,Self-Correcting Bayesian Optimization through Bayesian Active Learning60vanilla_1
Nugget: Neural Agglomerative Embeddings of Text,ICML,22,"Humeau, H., Das, R., Shuster, K., & Weston, J.",4.0,Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring,2020.0,International Conference on Learning Representations,3e216b4579a02e379738cc11014c8c44e33154c2,Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring,,,2019.0,"Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, J. Weston",4.0,172.0,30.0,26.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,82.0,1.0,Nugget: Neural Agglomerative Embeddings of Text22,113.0,113.0,ICLR,,vanilla_1,1,Nugget: Neural Agglomerative Embeddings of Text22vanilla_1
Precise Regret Bounds for Log-loss via a Truncated Bayesian Algorithm,NeurIPS,37,"Pierre Gaillard, Olivier Wintenberger",2.0,One Mic Mac Minka: Large Scale Automatic Bagging,2016.0,Journal of Machine Learning Research,,,,,,,,,,,,,,0.0,0.0,1.0,,,0.0,Precise Regret Bounds for Log-loss via a Truncated Bayesian Algorithm37,48.0,,JMLR,,vanilla_1,0,Precise Regret Bounds for Log-loss via a Truncated Bayesian Algorithm37vanilla_1
"Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport",ICLR,28,"Liu, D. C., Nocedal, J., Waltz, R. A., & Bretthorst, G. L.",4.0,Parameter Selection in Limited Memory Matrix Methods for Large Scale Optimization,2001.0,Numerical Analysis and Scientific Computing,,,,,,,,,,,,,,,,,62.0,29.0,0.0,"Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport28",81.0,,Numerical Analysis and Scientific Computing,,vanilla_1,0,"Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport28vanilla_1"
Bridging the Gap Between Vision Transformers and Convolutional Neural Networks on Small Datasets,NeurIPS,2,"He, K., Zhang, X., Ren, S. and Sun, J.",4.0,Deep Residual Learning for Image Recognition,2016.0,IEEE Conference on Computer Vision and Pattern Recognition,2c03df8b48bf3fa39054345bafabfeff15bfd11d,Deep Residual Learning for Image Recognition,Computer Vision and Pattern Recognition,Computer Vision and Pattern Recognition,2015.0,"Kaiming He, X. Zhang, Shaoqing Ren, Jian Sun",4.0,146861.0,30475.0,54.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,78.0,1.0,Bridging the Gap Between Vision Transformers and Convolutional Neural Networks on Small Datasets2,44.0,44.0,CVPR,CVPR,vanilla_1,0,Bridging the Gap Between Vision Transformers and Convolutional Neural Networks on Small Datasets2vanilla_1
Combining Explicit and Implicit Regularization for Efficient Learning in Deep Networks,NeurIPS,9,"Hoyer, P. O.",1.0,Non-negative matrix factorization with sparseness constraints.,2004.0,"Journal of machine learning research, 5(Nov)",ede3af3637977988b8cbb330c294183e919b7d5a,Non-negative Matrix Factorization with Sparseness Constraints,Journal of machine learning research,Journal of machine learning research,2004.0,P. Hoyer,1.0,2866.0,289.0,28.0,False,"['Mathematics', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Combining Explicit and Implicit Regularization for Efficient Learning in Deep Networks9,62.0,61.0,JMLR,JMLR,vanilla_1,1,Combining Explicit and Implicit Regularization for Efficient Learning in Deep Networks9vanilla_1
"A Fast, Well-Founded Approximation to the Empirical Neural Tangent Kernel",ICML,19,"Krizhevsky, A., & Hinton, G.",2.0,Learning multiple layers of features from tiny images,2009.0,"Technical report, University of Toronto",5d90f06bb70a0a3dced62413346235c02b1aa086,Learning Multiple Layers of Features from Tiny Images,,,2009.0,A. Krizhevsky,1.0,26240.0,8115.0,15.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,100.0,1.0,"A Fast, Well-Founded Approximation to the Empirical Neural Tangent Kernel19",53.0,53.0,"Technical report, University of Toronto",,vanilla_1,1,"A Fast, Well-Founded Approximation to the Empirical Neural Tangent Kernel19vanilla_1"
FunkNN: Neural Interpolation for Functional Generation,ICLR,19,"Ho, J., Chen, X., Xie, E., Duan, Y., & Abbeel, P.",5.0,Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design,2019.0,ICML,c8b25a128f4bfd0c79de82c174dd403b2ef6eeb1,Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design,International Conference on Machine Learning,International Conference on Machine Learning,2019.0,"Jonathan Ho, Xi Chen, A. Srinivas, Yan Duan, P. Abbeel",5.0,365.0,48.0,40.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,78.0,1.0,FunkNN: Neural Interpolation for Functional Generation19,102.0,102.0,ICML,ICML,vanilla_1,0,FunkNN: Neural Interpolation for Functional Generation19vanilla_1
Noise Injection Node Regularization for Robust Learning,ICLR,5,P. G. Drazin,1.0,Nonlinear Systems,1992.0,Cambridge University Press,,,,,,,,,,,,,,,,,100.0,26.0,0.0,Noise Injection Node Regularization for Robust Learning5,17.0,,Cambridge University Press,,vanilla_1,0,Noise Injection Node Regularization for Robust Learning5vanilla_1
Mirror Descent Maximizes Generalized Margin and Can Be Implemented Efficiently,NeurIPS,21,"Fawzi, A., Frossard, P.",2.0,Analysis of classifiers' robustness to adversarial perturbations,2018.0,Machine learning,f02441fccec9ed54dd7e21a17736933c84853011,Analysis of classifiers’ robustness to adversarial perturbations,Machine-mediated learning,Machine-mediated learning,2015.0,"Alhussein Fawzi, Omar Fawzi, P. Frossard",3.0,331.0,20.0,43.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,98.0,94.0,1.0,Mirror Descent Maximizes Generalized Margin and Can Be Implemented Efficiently21,64.0,64.0,Machine learning,Machine-mediated learning,vanilla_1,0,Mirror Descent Maximizes Generalized Margin and Can Be Implemented Efficiently21vanilla_1
Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation,NeurIPS,19,"Spirtes, P., Glymour, C. N., Scheines, R.",3.0,"Causation, prediction, and search",2000.0,MIT press,5b3b9fe128e6849d59a26d7ceda57baad2524815,"Causation, prediction, and search",,,1993.0,"P. Spirtes, C. Glymour, R. Scheines",3.0,2790.0,230.0,146.0,True,['Mathematics'],"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation19,33.0,33.0,MIT press,,vanilla_1,0,Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation19vanilla_1
Precise Regret Bounds for Log-loss via a Truncated Bayesian Algorithm,NeurIPS,9,Yuri M. Shtarkov,1.0,Universal Sequential Coding of Single Messages,1987.0,Problems of Information Transmission,,,,,,,,,,,,,,,,,48.0,24.0,0.0,Precise Regret Bounds for Log-loss via a Truncated Bayesian Algorithm9,46.0,,Problems of Information Transmission,,vanilla_1,0,Precise Regret Bounds for Log-loss via a Truncated Bayesian Algorithm9vanilla_1
Efficient Aggregated Kernel Tests using Incomplete $U$-statistics,NeurIPS,22,"Efron, B. & Tibshirani, R.",2.0,An Introduction to the Bootstrap,1993.0,CRC Press,85a8a97f614b2b6823e035bcc9abcb0f3d27be4d,An Introduction to the Bootstrap,,,1994.0,"B. Efron, R. Tibshirani",2.0,23010.0,345.0,0.0,True,"['Mathematics', 'Sociology', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}, {'category': 'Sociology', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Efficient Aggregated Kernel Tests using Incomplete $U$-statistics22,32.0,32.0,CRC Press,,vanilla_1,1,Efficient Aggregated Kernel Tests using Incomplete $U$-statistics22vanilla_1
Efficient Graph Field Integrators Meet Point Clouds,ICML,25,"Cuturi, M.",1.0,Sinkhorn distances: Lightspeed computation of optimal transport,2013.0,Advances in neural information processing systems,0080118b0eb02af581ff32b85a1bb6aed7081f45,Sinkhorn Distances: Lightspeed Computation of Optimal Transport,Neural Information Processing Systems,Neural Information Processing Systems,2013.0,Marco Cuturi,1.0,3079.0,561.0,37.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",1.0,0.0,0.0,100.0,86.0,1.0,Efficient Graph Field Integrators Meet Point Clouds25,63.0,63.0,NeurIPS,NeurIPS,vanilla_1,1,Efficient Graph Field Integrators Meet Point Clouds25vanilla_1
Curriculum Reinforcement Learning using Optimal Transport via Gradual Domain Adaptation,NeurIPS,15,"Garg, A., Kapoor, A., & Mahajan, K.",3.0,Provable smoothness guarantees for black-box optimization with bandits,2020.0,NeurIPS,,,,,,,,,,,,,,0.0,0.0,1.0,,,0.0,Curriculum Reinforcement Learning using Optimal Transport via Gradual Domain Adaptation15,70.0,,NeurIPS,,vanilla_1,1,Curriculum Reinforcement Learning using Optimal Transport via Gradual Domain Adaptation15vanilla_1
FunkNN: Neural Interpolation for Functional Generation,ICLR,11,"Mildenhall, B., Srinivasan, P. P., Tancik, M., Barron, J. T., Ramamoorthi, R., & Ng, R.",6.0,NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis,2020.0,ECCV,428b663772dba998f5dc6a24488fff1858a0899f,NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis,European Conference on Computer Vision,European Conference on Computer Vision,2020.0,"B. Mildenhall, Pratul P. Srinivasan, Matthew Tancik, J. Barron, R. Ramamoorthi, Ren Ng",6.0,3212.0,996.0,58.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,97.0,1.0,FunkNN: Neural Interpolation for Functional Generation11,70.0,70.0,ECCV,European Conference on Computer Vision,vanilla_1,0,FunkNN: Neural Interpolation for Functional Generation11vanilla_1
Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts,ICLR,32,D. Lopez-Paz,1.0,Algorithmic Robustness: From Classifiers to Autocorrelation,2015.0,International Conference on Artificial Intelligence and Statistics,,,,,,,,,,,,,,,,,44.0,26.0,0.0,Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts32,59.0,,International Conference on Artificial Intelligence and Statistics,,vanilla_1,0,Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts32vanilla_1
Instance-based Learning for Knowledge Base Completion,NeurIPS,16,"Paulheim, H.",1.0,Knowledge Graph Refinement: A survey of approaches and evaluation methods,2017.0,Semantic Web,53f1779c4169b128072e6f50dc3f31bb2c530a70,Knowledge graph refinement: A survey of approaches and evaluation methods,Semantic Web,,2016.0,Heiko Paulheim,1.0,931.0,65.0,127.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,89.0,1.0,Instance-based Learning for Knowledge Base Completion16,73.0,73.0,Semantic Web,Semantic Web,vanilla_1,0,Instance-based Learning for Knowledge Base Completion16vanilla_1
Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency,NeurIPS,29,"Redmon, J., & Farhadi, A.",2.0,"YOLO9000: better, faster, stronger",2017.0,Proceedings of the IEEE conference on computer vision and pattern recognition,7d39d69b23424446f0400ef603b2e3e22d0309d6,"YOLO9000: Better, Faster, Stronger",Computer Vision and Pattern Recognition,Computer Vision and Pattern Recognition,2016.0,"Joseph Redmon, Ali Farhadi",2.0,12113.0,1514.0,20.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,88.0,1.0,Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency29,34.0,34.0,CVPR,CVPR,vanilla_1,0,Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency29vanilla_1
Approximately Optimal Core Shapes for Tensor Decompositions,ICML,7,"Oseledets, I. V, & Savostyanov, D. V.",2.0,Optimal rank tensor approximation: new idea in numerical tensor calculus,2011.0,"Russian Academy of Sciences, Universitetskaya",,,,,,,,,,,,,,,,,41.0,32.0,0.0,Approximately Optimal Core Shapes for Tensor Decompositions7,72.0,,"Russian Academy of Sciences, Universitetskaya",,vanilla_1,1,Approximately Optimal Core Shapes for Tensor Decompositions7vanilla_1
Personalized Prediction of Recurrent Stress Events Using Self-Supervised Learning on Multimodal Time-Series Data,ICML,5,"Healey, J., & Picard, R.",2.0,Detecting stress during real-world driving tasks using physiological sensors,2005.0,"Intelligent Transportation Systems, IEEE Transactions on",0a69f74ca6dfcae8509e62725fd5c0e6999a81ef,Detecting stress during real-world driving tasks using physiological sensors,IEEE transactions on intelligent transportation systems (Print),,2005.0,"Jennifer Healey, Rosalind W. Picard",2.0,1796.0,186.0,43.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,87.0,1.0,Personalized Prediction of Recurrent Stress Events Using Self-Supervised Learning on Multimodal Time-Series Data5,76.0,76.0,"Intelligent Transportation Systems, IEEE Transactions on",IEEE transactions on intelligent transportation systems (Print),vanilla_1,0,Personalized Prediction of Recurrent Stress Events Using Self-Supervised Learning on Multimodal Time-Series Data5vanilla_1
Reinforcement Learning with General Utilities: Simpler Variance Reduction and Large State-Action Space,ICML,41,"Zhang, K., Luo, Z., & Zhou, Z.",3.0,Composite Objective mirror descent,2013.0,Proceedings International Conference on Machine Learning,,,,,,,,,,,,,,,,,100.0,43.0,0.0,Reinforcement Learning with General Utilities: Simpler Variance Reduction and Large State-Action Space41,34.0,,ICML,,vanilla_1,0,Reinforcement Learning with General Utilities: Simpler Variance Reduction and Large State-Action Space41vanilla_1
Accelerated Federated Learning with Decoupled Adaptive Optimization,ICML,19,"Lichiardopol, S.",1.0,An overview of gradient descent optimization algorithms,2017.0,arXiv preprint arXiv:1706.04838,,,,,,,,,,,,,,,,,100.0,28.0,0.0,Accelerated Federated Learning with Decoupled Adaptive Optimization19,55.0,,arxiv,,vanilla_1,0,Accelerated Federated Learning with Decoupled Adaptive Optimization19vanilla_1
Differentiable Analog Quantum Computing for Optimization and Control,NeurIPS,12,"Preskill, J.",1.0,Quantum Computing in the NISQ era and beyond,2018.0,Quantum 2,f3d594544126e202dbd81c186ca3ce448af5255c,Quantum Computing in the NISQ era and beyond,Quantum,Quantum,2018.0,J. Preskill,1.0,4842.0,306.0,77.0,True,"['Physics', 'Computer Science']","[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Differentiable Analog Quantum Computing for Optimization and Control12,44.0,44.0,Quantum 2,Quantum,vanilla_1,1,Differentiable Analog Quantum Computing for Optimization and Control12vanilla_1
FastAMI -- a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics,AAAI,11,"Vinh, N. X., Epps, J. and Bailey, J.",3.0,"Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance",2010.0,Journal of Machine Learning Research,259da70238f076c670c6cc2901b82b3f20d472df,"Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance",Journal of machine learning research,Journal of machine learning research,2010.0,"X. Nguyen, J. Epps, J. Bailey",3.0,1848.0,354.0,32.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,81.0,1.0,FastAMI -- a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics11,120.0,120.0,JMLR,JMLR,vanilla_1,1,FastAMI -- a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics11vanilla_1
Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias,NeurIPS,11,"Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I.",6.0,Language models are unsupervised multitask learners,2019.0,OpenAI Blog,9405cc0d6169988371b2755e573cc28650d14dfe,Language Models are Unsupervised Multitask Learners,,,2019.0,"Alec Radford, Jeff Wu, Rewon Child, D. Luan, Dario Amodei, Ilya Sutskever",6.0,13112.0,2723.0,75.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,91.0,1.0,Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias11,51.0,51.0,OpenAI Blog,,vanilla_1,1,Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias11vanilla_1
Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity,NeurIPS,3,M. Arpit et al.,et al.,A Closer Look at Memorization in Deep Networks,2017.0,Proceedings of the 34th International Conference on Machine Learning (ICML),5ddd38a5df945e4afee68d96ed51fd6ca1f7d4cf,A Closer Look at Memorization in Deep Networks,International Conference on Machine Learning,International Conference on Machine Learning,2017.0,"Devansh Arpit, Stanislaw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S. Kanwal, Tegan Maharaj, Asja Fischer, Aaron C. Courville, Yoshua Bengio, Simon Lacoste-Julien",11.0,1364.0,132.0,42.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,56.0,1.0,Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity3,46.0,46.0,ICML,ICML,vanilla_1,0,Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity3vanilla_1
On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $ε$-Greedy Exploration,NeurIPS,60,"Pugh, J.K., Soros, L.B., Stanley, K.O.",3.0,Quality diversity: A new frontier for evolutionary computation,2016.0,Frontiers in Robotics and AI,eaa518ad767dae7875f7f8fbc9eca6e05f9d11d0,Quality Diversity: A New Frontier for Evolutionary Computation,Frontiers in Robotics and AI,Frontiers in Robotics and AI,2016.0,"Justin K. Pugh, L. Soros, Kenneth O. Stanley",3.0,433.0,50.0,62.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,92.0,1.0,On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $ε$-Greedy Exploration60,62.0,62.0,Frontiers in Robotics and AI,Frontiers in Robotics and AI,vanilla_1,0,On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $ε$-Greedy Exploration60vanilla_1
Eagle: Large-Scale Learning of Turbulent Fluid Dynamics with Mesh Transformers,ICLR,5,M. Thuerey,1.0,Data-driven Fluid Simulations using Regression Forests,2015.0,"Computer Graphics Forum 34, no. 8",,,,,,,,,,,,,,,,,100.0,20.0,0.0,Eagle: Large-Scale Learning of Turbulent Fluid Dynamics with Mesh Transformers5,54.0,,"Computer Graphics Forum 34, no. 8",,vanilla_1,0,Eagle: Large-Scale Learning of Turbulent Fluid Dynamics with Mesh Transformers5vanilla_1
Repository-Level Prompt Generation for Large Language Models of Code,ICML,1,"Rudder, B., Klein, J., & Perry, D.",3.0,Using Large Language Models to Power Code Assistants,2019.0,The Journal of Machine Learning Research,,,,,,,,,,,,,,,,,81.0,34.0,0.0,Repository-Level Prompt Generation for Large Language Models of Code1,52.0,,JMLR,,vanilla_1,0,Repository-Level Prompt Generation for Large Language Models of Code1vanilla_1
InfoOT: Information Maximizing Optimal Transport,ICML,20,"Pan, S. J., Tsang, I. W., Kwok, J. T., & Yang, Q.",4.0,Domain adaptation via transfer component analysis,2011.0,IEEE Transactions on Neural Networks,1dae4d61cd74cc919ecc638bde6b7125728ea97b,Domain Adaptation via Transfer Component Analysis,IEEE Transactions on Neural Networks,IEEE Transactions on Neural Networks,2009.0,"Sinno Jialin Pan, I. Tsang, J. Kwok, Qiang Yang",4.0,3406.0,635.0,55.0,True,"['Computer Science', 'Medicine', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,85.0,1.0,InfoOT: Information Maximizing Optimal Transport20,49.0,49.0,IEEE Transactions on Neural Networks,IEEE Transactions on Neural Networks,vanilla_1,0,InfoOT: Information Maximizing Optimal Transport20vanilla_1
Effective Dimension in Bandit Problems under Censorship,NeurIPS,4,"Piccolboni, A., and Schindelhauer, C.",2.0,Discrete prediction games with arbitrary feedback and loss,2001.0,14th annual conference on Computational learning theory,eb3289c8315d3aa232587455107d9dea828cd1be,Discrete Prediction Games with Arbitrary Feedback and Loss,COLT/EuroCOLT,,2001.0,"A. Piccolboni, C. Schindelhauer",2.0,77.0,13.0,20.0,False,"['Mathematics', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Effective Dimension in Bandit Problems under Censorship4,58.0,58.0,14th annual conference on Computational learning theory,COLT/EuroCOLT,vanilla_1,0,Effective Dimension in Bandit Problems under Censorship4vanilla_1
Transformers learn to implement preconditioned gradient descent for in-context learning,NeurIPS,23,"Mao, Yuning, et al.",et al.,On transformer generalization and robustness,2020.0,Advances in Neural Information Processing Systems,,,,,,,,,,,,,,,,,55.0,41.0,0.0,Transformers learn to implement preconditioned gradient descent for in-context learning23,44.0,,NeurIPS,,vanilla_1,1,Transformers learn to implement preconditioned gradient descent for in-context learning23vanilla_1
RanPAC: Random Projections and Pre-trained Models for Continual Learning,NeurIPS,33,"Shin, Hanul, et al.",et al.,Continual learning with deep generative replay,2017.0,Advances in Neural Information Processing Systems,59a922212153d3407e658109f36c11a34ee7d283,Continual Learning with Deep Generative Replay,Neural Information Processing Systems,Neural Information Processing Systems,2017.0,"Hanul Shin, Jung Kwon Lee, Jaehong Kim, Jiwon Kim",4.0,1446.0,136.0,36.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,RanPAC: Random Projections and Pre-trained Models for Continual Learning33,46.0,46.0,NeurIPS,NeurIPS,vanilla_1,0,RanPAC: Random Projections and Pre-trained Models for Continual Learning33vanilla_1
Computational Doob's h-transforms for Online Filtering of Discretely Observed Diffusions,ICML,4,"Doucet, A., & Johansen, A. M.",2.0,A tutorial on particle filtering and smoothing: Fifteen years later.,2011.0,Handbook of nonlinear filtering,1cd44dd4f1b0b1c0499b1dc9637010c6d63d445c,A Tutorial on Particle Filtering and Smoothing: Fifteen years later,,,2008.0,"A. Doucet, A. M. Johansen",2.0,2021.0,191.0,40.0,False,['Mathematics'],"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Economics', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",1.0,0.0,0.0,100.0,100.0,1.0,Computational Doob's h-transforms for Online Filtering of Discretely Observed Diffusions4,68.0,67.0,Handbook of nonlinear filtering,,vanilla_1,0,Computational Doob's h-transforms for Online Filtering of Discretely Observed Diffusions4vanilla_1
An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning,ICML,53,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Polosukhin, I.",7.0,Attention is all you need,2017.0,Not mentioned,204e3073870fae3d05bcbc2f6a8e263d9b72e776,Attention is All you Need,Neural Information Processing Systems,Neural Information Processing Systems,2017.0,"Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin",8.0,75256.0,14339.0,42.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,0.0,0.0,100.0,93.0,1.0,An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning53,25.0,25.0,Not mentioned,NeurIPS,vanilla_1,0,An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning53vanilla_1
Maximum Common Subgraph Guided Graph Retrieval: Late and Early Interaction Networks,NeurIPS,47,"Yan, X., Guo, J., Lan, Y., Cheng, X.",4.0,A Biterm Topic Model for Short Texts,2008.0,Proceedings of the 22nd International Conference on World Wide Web,b7da93b0c797cdb2b5b31adc73224d625c0a0759,A biterm topic model for short texts,The Web Conference,The Web Conference,2013.0,"Xiaohui Yan, J. Guo, Yanyan Lan, Xueqi Cheng",4.0,906.0,152.0,34.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,90.0,1.0,Maximum Common Subgraph Guided Graph Retrieval: Late and Early Interaction Networks47,36.0,36.0,Proceedings of the 22nd International Conference on World Wide Web,The Web Conference,vanilla_1,1,Maximum Common Subgraph Guided Graph Retrieval: Late and Early Interaction Networks47vanilla_1
Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency,NeurIPS,12,"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K.",4.0,Bert: Pre-training of deep bidirectional transformers for language understanding,2018.0,arXiv preprint,df2b0e26d0599ce3e70df8a9da02e51594e0e992,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,North American Chapter of the Association for Computational Linguistics,North American Chapter of the Association for Computational Linguistics,2019.0,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova",4.0,64311.0,18118.0,63.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,0.0,0.0,100.0,87.0,1.0,Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency12,80.0,80.0,arxiv,North American Chapter of the Association for Computational Linguistics,vanilla_1,0,Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency12vanilla_1
QUILT: Effective Multi-Class Classification on Quantum Computers Using an Ensemble of Diverse Quantum Classifiers,AAAI,8,"Sutor, R. S.",1.0,Dancing with Qubits: How quantum computing works and how it can change the world,2019.0,Packt Publishing Ltd,,,,,,,,,,,,,,0.0,0.0,1.0,,,0.0,QUILT: Effective Multi-Class Classification on Quantum Computers Using an Ensemble of Diverse Quantum Classifiers8,80.0,,Packt Publishing Ltd,,vanilla_1,0,QUILT: Effective Multi-Class Classification on Quantum Computers Using an Ensemble of Diverse Quantum Classifiers8vanilla_1
Fast Nonlinear Vector Quantile Regression,ICLR,2,"Carlier, G., Chernozhukov, V., & Galichon, A.",3.0,Vector quantile regression: an optimal transport approach,2016.0,Annals of Statistics,,,,,,,,,,,,,,,,,89.0,97.0,0.0,Fast Nonlinear Vector Quantile Regression2,57.0,,Annals of Statistics,,vanilla_1,1,Fast Nonlinear Vector Quantile Regression2vanilla_1
Reinforcement Learning for Branch-and-Bound Optimisation using Retrospective Trajectories,AAAI,8,"Puterman, M.L.",1.0,Markov Decision Processes: Discrete Stochastic Dynamic Programming,2014.0,John Wiley & Sons,8090121ad488b4af27bc59bf91b62e9c6a6f49c6,Markov Decision Processes: Discrete Stochastic Dynamic Programming,,,1994.0,M. Puterman,1.0,12513.0,1795.0,6.0,False,['Mathematics'],"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Reinforcement Learning for Branch-and-Bound Optimisation using Retrospective Trajectories8,66.0,66.0,John Wiley & Sons,,vanilla_1,1,Reinforcement Learning for Branch-and-Bound Optimisation using Retrospective Trajectories8vanilla_1
Deep Contract Design via Discontinuous Networks,NeurIPS,45,"Rosenblatt, F.",1.0,The perceptron: a probabilistic model for information storage and organization in the brain,1958.0,Psychological review,,,,,,,,,,,,,,,,,100.0,22.0,0.0,Deep Contract Design via Discontinuous Networks45,91.0,,Psychological review,,vanilla_1,1,Deep Contract Design via Discontinuous Networks45vanilla_1
Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts,ICLR,7,"L. El Ghaoui, V. Vapnik",2.0,Robustness in the Optimization of Risk Measures,2018.0,Journal of Machine Learning Research,,,,,,,,,,,,,,,,,100.0,20.0,0.0,Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts7,47.0,,JMLR,,vanilla_1,0,Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group Shifts7vanilla_1
Self-Correcting Bayesian Optimization through Bayesian Active Learning,NeurIPS,3,"Osborne, M. A.",1.0,"Bayesian Gaussian Processes for Sequential Prediction, Optimisation and Quadrature",2010.0,"Doctoral dissertation, University of Oxford",74d6b7a3fda8ba7e9183ccbb8b697018b38864d7,"Bayesian Gaussian processes for sequential prediction, optimisation and quadrature",,,2010.0,Michael A. Osborne,1.0,140.0,11.0,92.0,False,['Mathematics'],"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,90.0,1.0,Self-Correcting Bayesian Optimization through Bayesian Active Learning3,82.0,82.0,"Doctoral dissertation, University of Oxford",,vanilla_1,0,Self-Correcting Bayesian Optimization through Bayesian Active Learning3vanilla_1
Stochastic Rising Bandits,ICML,21,"Lai, Tze Leung and Herbert Robbins",2.0,Asymptotically efficient adaptive allocation rules,1985.0,Advances in applied mathematics 6.1,4c9e36a0dbdc3e7b20e38bd288a804c05c77e9fa,Asymptotically efficient adaptive allocation rules,,,1985.0,"T. Lai, H. Robbins",2.0,1142.0,117.0,3.0,True,['Mathematics'],"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,85.0,1.0,Stochastic Rising Bandits21,50.0,50.0,Advances in applied mathematics 6.1,,vanilla_1,1,Stochastic Rising Bandits21vanilla_1
Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets,NeurIPS,9,"Liu, S., Abbeel, P., & Levine, S.",3.0,Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate Shift,2019.0,Neural Information Processing Systems (NeurIPS),,,,,,,,,,,,,,,,,100.0,35.0,0.0,Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets9,75.0,,NeurIPS,,vanilla_1,0,Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets9vanilla_1
Adaptive Selective Sampling for Online Prediction with Experts,NeurIPS,6,"Freund, Y., Seung, H. S., Shamir, E., & Tishby, N.",4.0,Selective sampling using the query by committee algorithm,1997.0,Machine learning,01dfd7b78017ea4059f02081680a9fd4b2bb2a34,Selective Sampling Using the Query by Committee Algorithm,Machine-mediated learning,Machine-mediated learning,1997.0,"Y. Freund, H. Seung, E. Shamir, Naftali Tishby",4.0,1187.0,60.0,39.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,94.0,1.0,Adaptive Selective Sampling for Online Prediction with Experts6,57.0,57.0,Machine learning,Machine-mediated learning,vanilla_1,0,Adaptive Selective Sampling for Online Prediction with Experts6vanilla_1
Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation,NeurIPS,21,"Dhurandhar, A., Saha, K.",2.0,Wishart's Distribution for Graphical Models and Causal Inference Learning,2018.0,arXiv preprint,,,,,,,,,,,,,,0.0,0.0,1.0,,,0.0,Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation21,73.0,,arxiv,,vanilla_1,0,Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation21vanilla_1
"Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation",ICLR,21,"Caruana, Rich",1.0,Multitask Learning: A Knowledge-Based Source of Inductive Bias,1993.0,Proceedings of the 10th International Workshop on Machine Learning,9464d15f4f8d578f93332db4aa1c9c182fd51735,Multitask Learning: A Knowledge-Based Source of Inductive Bias,International Conference on Machine Learning,International Conference on Machine Learning,1993.0,R. Caruana,1.0,881.0,84.0,20.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,88.0,1.0,"Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation21",62.0,62.0,Proceedings of the 10th International Workshop on Machine Learning,ICML,vanilla_1,1,"Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation21vanilla_1"
Deep Contract Design via Discontinuous Networks,NeurIPS,48,"Rakhlin, A., & Sridharan, K.",2.0,Online learning with noisy side observations,2016.0,Artificial Intelligence and Statistics,,,,,,,,,,,,,,,,,100.0,29.0,0.0,Deep Contract Design via Discontinuous Networks48,44.0,,Artificial Intelligence and Statistics,,vanilla_1,0,Deep Contract Design via Discontinuous Networks48vanilla_1
Instance-optimal PAC Algorithms for Contextual Bandits,NeurIPS,9,"S. Agrawal, N. Goyal",2.0,Analysis of Thompson Sampling for the multi-armed bandit problem,2012.0,Conf on Learning Theory COLT,ea4ffbb3d628cd0739b04b67a1d4c3c7ccf75beb,Analysis of Thompson Sampling for the Multi-armed Bandit Problem,Annual Conference Computational Learning Theory,Annual Conference Computational Learning Theory,2011.0,"Shipra Agrawal, Navin Goyal",2.0,1065.0,130.0,17.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,87.0,1.0,Instance-optimal PAC Algorithms for Contextual Bandits9,64.0,64.0,Conf on Learning Theory COLT,Annual Conference Computational Learning Theory,vanilla_1,1,Instance-optimal PAC Algorithms for Contextual Bandits9vanilla_1
Computational Asymmetries in Robust Classification,ICML,6,"F. Tramèr, A. Kurakin, N. Papernot, I. Goodfellow, D. Boneh, P. McDaniel",6.0,Ensemble Adversarial Training: Attacks and Defenses,2018.0,International Conference on Learning Representations,136dee73f203df2f4831994bf4f0c0a4ad2e764e,Ensemble Adversarial Training: Attacks and Defenses,International Conference on Learning Representations,International Conference on Learning Representations,2017.0,"Florian Tramèr, Alexey Kurakin, Nicolas Papernot, D. Boneh, P. Mcdaniel",5.0,2278.0,270.0,61.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,81.0,1.0,Computational Asymmetries in Robust Classification6,51.0,51.0,ICLR,ICLR,vanilla_1,0,Computational Asymmetries in Robust Classification6vanilla_1
Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks,AAAI,9,"Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z. B., & Swami, A.",6.0,Practical black-box attacks against machine learning,2016.0,Proceedings of the 2017 ACM on Asia conference on computer and communications security,53b047e503f4c24602f376a774d653f7ed56c024,Practical Black-Box Attacks against Machine Learning,ACM Asia Conference on Computer and Communications Security,ACM Asia Conference on Computer and Communications Security,2016.0,"Nicolas Papernot, P. Mcdaniel, I. Goodfellow, S. Jha, Z. B. Celik, A. Swami",6.0,3060.0,241.0,41.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,98.0,1.0,Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks9,52.0,52.0,Proceedings of the 2017 ACM on Asia conference on computer and communications security,ACM Asia Conference on Computer and Communications Security,vanilla_1,0,Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks9vanilla_1
Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning,ICML,4,"W. Lingzi, H. Anbang, S. Xiaogang",3.0,Symmetrical Metrics for Object Segmentation,2021.0,IEEE Transactions on Image Processing,,,,,,,,,,,,,,,,,53.0,30.0,0.0,Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning4,43.0,,IEEE Transactions on Image Processing,,vanilla_1,0,Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning4vanilla_1
Canonical normalizing flows for manifold learning,NeurIPS,16,"Lawrence, N.D., Seeger, M., Rasmussen, C.E.",3.0,Fast Sparse Gaussian Process Methods: The Informative Vector Machine,2002.0,Advances in Neural Information Processing Systems,fde4bf50d48d54ba913d574c849566dc4f3d4fde,Fast Sparse Gaussian Process Methods: The Informative Vector Machine,Neural Information Processing Systems,Neural Information Processing Systems,2002.0,"Neil D. Lawrence, M. Seeger, R. Herbrich",3.0,583.0,46.0,10.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,71.0,1.0,Canonical normalizing flows for manifold learning16,68.0,68.0,NeurIPS,NeurIPS,vanilla_1,1,Canonical normalizing flows for manifold learning16vanilla_1
On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $ε$-Greedy Exploration,NeurIPS,55,"Osband, I., Blundell, C., Pritzel, A., Van Roy, B.",4.0,Deep exploration via bootstrapped DQN,2016.0,Advances in neural information processing systems,4b63e34276aa98d5345efa7fe09bb06d8a9d8f52,Deep Exploration via Bootstrapped DQN,Neural Information Processing Systems,Neural Information Processing Systems,2016.0,"Ian Osband, C. Blundell, A. Pritzel, Benjamin Van Roy",4.0,1071.0,182.0,48.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,95.0,1.0,On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $ε$-Greedy Exploration55,37.0,37.0,NeurIPS,NeurIPS,vanilla_1,0,On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $ε$-Greedy Exploration55vanilla_1
Increasing the Scope as You Learn: Adaptive Bayesian Optimization in Nested Subspaces,NeurIPS,13,"Tedrake, R.",1.0,LQR-Trees: Feedback motion planning via sums-of-squares verification,2014.0,The International Journal of Robotics Research,36256596180fe57c345210057bc360a7024bfc9d,LQR-trees: Feedback Motion Planning via Sums-of-Squares Verification,Int. J. Robotics Res.,,2010.0,"Russ Tedrake, I. Manchester, Mark M. Tobenkin, John W. Roberts",4.0,455.0,25.0,42.0,True,"['Mathematics', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,88.0,1.0,Increasing the Scope as You Learn: Adaptive Bayesian Optimization in Nested Subspaces13,68.0,68.0,The International Journal of Robotics Research,Int. J. Robotics Res.,vanilla_1,0,Increasing the Scope as You Learn: Adaptive Bayesian Optimization in Nested Subspaces13vanilla_1
Generalization Bounds with Data-dependent Fractal Dimensions,ICML,5,"Deligiannidis, G., Lyons, T., & Nikeghbali, A.",3.0,A solution to the sign problem in a frustrated quantum system,2019.0,Nature Physics,,,,,,,,,,,,,,0.0,0.0,1.0,,,0.0,Generalization Bounds with Data-dependent Fractal Dimensions5,61.0,,Nature,,vanilla_1,1,Generalization Bounds with Data-dependent Fractal Dimensions5vanilla_1
A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model,ICLR,8,"Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., ... & Shi, W.",9.0,Photo-realistic single image super-resolution using a generative adversarial network,2017.0,Proceedings of the IEEE conference on computer vision and pattern recognition,df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3,Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network,Computer Vision and Pattern Recognition,Computer Vision and Pattern Recognition,2016.0,"C. Ledig, Lucas Theis, Ferenc Huszár, Jose Caballero, Andrew P. Aitken, A. Tejani, J. Totz, Zehan Wang, Wenzhe Shi",9.0,8729.0,1184.0,77.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model8,84.0,84.0,CVPR,CVPR,vanilla_1,0,A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model8vanilla_1
Certified Neural Network Watermarks with Randomized Smoothing,ICML,8,"Zhang, J., et al.",et al.,Protecting Intellectual Property of Deep Neural Networks with Watermarking,2018.0,Proceedings of the 2018 ACM Asia Conference on Computer and Communications Security,97e748935bef3db297b90aed736064a51e68668d,Protecting Intellectual Property of Deep Neural Networks with Watermarking,ACM Asia Conference on Computer and Communications Security,ACM Asia Conference on Computer and Communications Security,2018.0,"Jialong Zhang, Zhongshu Gu, Jiyong Jang, Hui Wu, M. Stoecklin, Heqing Huang, Ian Molloy",7.0,398.0,63.0,58.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,62.0,1.0,Certified Neural Network Watermarks with Randomized Smoothing8,74.0,74.0,Proceedings of the 2018 ACM Asia Conference on Computer and Communications Security,ACM Asia Conference on Computer and Communications Security,vanilla_1,1,Certified Neural Network Watermarks with Randomized Smoothing8vanilla_1
Query-based Hard-Image Retrieval for Object Detection at Test Time,AAAI,16,"Weinberger, K. Q., & Saul, L. K.",2.0,Distance metric learning for large margin nearest neighbor classification,2009.0,Journal of Machine Learning Research,78947497cbbffc691aac3f590d972130259af9ce,Distance Metric Learning for Large Margin Nearest Neighbor Classification,Neural Information Processing Systems,Neural Information Processing Systems,2005.0,"Kilian Q. Weinberger, L. Saul",2.0,5527.0,724.0,35.0,False,"['Mathematics', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,95.0,1.0,Query-based Hard-Image Retrieval for Object Detection at Test Time16,73.0,73.0,JMLR,NeurIPS,vanilla_1,0,Query-based Hard-Image Retrieval for Object Detection at Test Time16vanilla_1
A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model,ICLR,20,"Vondrick, C., Pirsiavash, H., & Torralba, A.",3.0,Generating videos with scene dynamics,2016.0,Advances in neural information processing systems,ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1,Generating Videos with Scene Dynamics,Neural Information Processing Systems,Neural Information Processing Systems,2016.0,"Carl Vondrick, H. Pirsiavash, A. Torralba",3.0,1316.0,142.0,60.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,97.0,1.0,A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model20,37.0,37.0,NeurIPS,NeurIPS,vanilla_1,0,A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model20vanilla_1
On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $ε$-Greedy Exploration,NeurIPS,65,"Baird, Leemon C.",1.0,Residual algorithms: Reinforcement learning with function approximation,1995.0,Machine Learning Proceedings,f518bffb712a298bff18248c67f6fc0181018ae6,Residual Algorithms: Reinforcement Learning with Function Approximation,International Conference on Machine Learning,International Conference on Machine Learning,1995.0,L. Baird,1.0,1168.0,160.0,14.0,True,"['Mathematics', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,83.0,1.0,On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $ε$-Greedy Exploration65,71.0,71.0,Machine Learning Proceedings,ICML,vanilla_1,0,On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $ε$-Greedy Exploration65vanilla_1
Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias,NeurIPS,17,"Jernite, Y., Rush, A. M., & Sontag, D.",3.0,Pretraining by Prompting,2021.0,ArXiv preprint arXiv:2108.13044,,,,,,,,,,,,,,,,,62.0,33.0,0.0,Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias17,24.0,,arxiv,,vanilla_1,0,Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias17vanilla_1
RenyiCL: Contrastive Representation Learning with Skew Renyi Divergence,NeurIPS,27,"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Michael C. Mozer, Yoram Singer",5.0,Kernel Methods for Deep Learning,2020.0,Advances in Neural Information Processing Systems,,,,,,,,,,,,,,,,,100.0,28.0,0.0,RenyiCL: Contrastive Representation Learning with Skew Renyi Divergence27,32.0,,NeurIPS,,vanilla_1,1,RenyiCL: Contrastive Representation Learning with Skew Renyi Divergence27vanilla_1
ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges,AAAI,10,Z. Dong et al,et al.,Epileptiform Discharges in Patients Predict Refractory Epilepsy,2013.0,Neuropsychiatric Disease and Treatment,,,,,,,,,,,,,,,,,89.0,15.0,0.0,ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges10,63.0,,Neuropsychiatric Disease and Treatment,,vanilla_1,0,ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges10vanilla_1
Repository-Level Prompt Generation for Large Language Models of Code,ICML,6,"White, M., & Vendome, C.",2.0,Evaluation of line-level maintenance setting for code assistance.,2021.0,Proceedings of the 43rd International Conference on Software Engineering (ICSE),,,,,,,,,,,,,,,,,35.0,30.0,0.0,Repository-Level Prompt Generation for Large Language Models of Code6,65.0,,Proceedings of the 43rd International Conference on Software Engineering (ICSE),,vanilla_1,0,Repository-Level Prompt Generation for Large Language Models of Code6vanilla_1
A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model,ICLR,21,"Wu, J., Zhang, C., Xue, T., Freeman, B., & Tenenbaum, J.",5.0,Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling,2016.0,Advances in neural information processing systems,76cee11c6a9f1424f03571378a966c1417ff2935,Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling,Neural Information Processing Systems,Neural Information Processing Systems,2016.0,"Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, J. Tenenbaum",5.0,1683.0,136.0,49.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,91.0,1.0,A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model21,93.0,93.0,NeurIPS,NeurIPS,vanilla_1,0,A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model21vanilla_1
Concentration of Data Encoding in Parameterized Quantum Circuits,NeurIPS,17,"G. Evenbly, G. Vidal",2.0,Quantum criticality with the multi-scale entanglement renormalization ansatz,2013.0,Strongly correlated systems: numerical methods,9ac5d7c3501bdb8e7b96496111298f78139aa6c3,Quantum Criticality with the Multi-scale Entanglement Renormalization Ansatz,,,2011.0,"G. Evenbly, G. Vidal",2.0,100.0,5.0,55.0,True,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Concentration of Data Encoding in Parameterized Quantum Circuits17,76.0,76.0,arxiv,,vanilla_1,0,Concentration of Data Encoding in Parameterized Quantum Circuits17vanilla_1
Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation,NeurIPS,15,"Morgan, S. L., Winship, C.",2.0,Counterfactuals and causal inference,2014.0,Cambridge University Press,ff2d90db5ad92a97f63c1053673f04b3b3139e7f,Counterfactuals and Causal Inference: Methods and Principles for Social Research,,,2007.0,"S. Morgan, Christopher Winship",2.0,1839.0,120.0,249.0,False,['Psychology'],"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,89.0,1.0,Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation15,36.0,80.0,Cambridge University Press,,vanilla_1,0,Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation15vanilla_1
Generalization Bounds with Data-dependent Fractal Dimensions,ICML,1,"Vapnik, V. N.",1.0,Statistical learning theory,1998.0,,8213dbed4db44e113af3ed17d6dad57471a0c048,The Nature of Statistical Learning Theory,Statistics for Engineering and Information Science,,2000.0,V. Vapnik,1.0,41016.0,4158.0,71.0,True,"['Mathematics', 'Political Science', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Generalization Bounds with Data-dependent Fractal Dimensions1,27.0,41.0,,Statistics for Engineering and Information Science,vanilla_1,1,Generalization Bounds with Data-dependent Fractal Dimensions1vanilla_1
Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series,NeurIPS,2,C. Brooks,1.0,Introductory econometrics for finance,2014.0,Cambridge university press,ee80280380ed8ca7fcdf0f5dbeb66ebf1b8fa6dd,Introductory Econometrics for Finance,,,2002.0,Chris Brooks,1.0,3426.0,564.0,321.0,True,"['Economics', 'Mathematics', 'Computer Science']","[{'category': 'Economics', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,86.0,1.0,Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series2,37.0,37.0,Cambridge university press,,vanilla_1,0,Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series2vanilla_1
A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model,ICLR,23,"Girdhar, R., Fouhey, D. F., Rodriguez, M., & Gupta, A.",4.0,Learning a predictable and generative vector representation for objects,2016.0,"European Conference on Computer Vision, Springer, Cham",553a566dee3438ddff7d97a91e91d8a7b0caad66,Learning a Predictable and Generative Vector Representation for Objects,European Conference on Computer Vision,European Conference on Computer Vision,2016.0,"Rohit Girdhar, D. Fouhey, Mikel D. Rodriguez, A. Gupta",4.0,644.0,58.0,44.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,92.0,1.0,A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model23,71.0,71.0,"European Conference on Computer Vision, Springer, Cham",European Conference on Computer Vision,vanilla_1,0,A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model23vanilla_1
Exact Inference in High-order Structured Prediction,ICML,2,"C. Papadimitriou, K. Steiglitz",2.0,Binary Markov Random Fields and the Max-Cut Problem,,,,,,,,,,,,,,,,,,,32.0,25.0,0.0,Exact Inference in High-order Structured Prediction2,51.0,,,,vanilla_1,1,Exact Inference in High-order Structured Prediction2vanilla_1
An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning,ICML,35,"Wang, J. X., Kurth-Nelson, Z., Tirumala, D., Soyer, H., Leibo, J. Z., Munos, R., Botvinick, M.",7.0,Learning to reinforcement learn,2016.0,arXiv preprint,282a380fb5ac26d99667224cef8c630f6882704f,Learning to reinforcement learn,Annual Meeting of the Cognitive Science Society,Annual Meeting of the Cognitive Science Society,2016.0,"Jane X. Wang, Z. Kurth-Nelson, Hubert Soyer, Joel Z. Leibo, Dhruva Tirumala, R. Munos, C. Blundell, D. Kumaran, M. Botvinick",9.0,842.0,103.0,52.0,False,"['Mathematics', 'Psychology', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,97.0,1.0,An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning35,31.0,31.0,arxiv,Annual Meeting of the Cognitive Science Society,vanilla_1,0,An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning35vanilla_1
Learning Topology-Specific Experts for Molecular Property Prediction,AAAI,1,"Battaglia, P. W., Hamrick, J. B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi, V., Malinowski, M., ... & Raposo, D.",et al.,"Relational inductive biases, deep learning, and graph networks",2018.0,arXiv preprint arXiv:1806.01261,3a58efcc4558727cc5c131c44923635da4524f33,"Relational inductive biases, deep learning, and graph networks",arXiv.org,arXiv.org,2018.0,"P. Battaglia, Jessica B. Hamrick, V. Bapst, Alvaro Sanchez-Gonzalez, V. Zambaldi, Mateusz Malinowski, A. Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Çaglar Gülçehre, H. F. Song, A. J. Ballard, J. Gilmer, George E. Dahl, Ashish Vaswani, Kelsey R. Allen, C. Nash, Victoria Langston, Chris Dyer, N. Heess, Daan Wierstra, Pushmeet Kohli, M. Botvinick, Oriol Vinyals, Yujia Li, Razvan Pascanu",27.0,2456.0,247.0,200.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Learning Topology-Specific Experts for Molecular Property Prediction1,62.0,62.0,arxiv,arxiv,vanilla_1,0,Learning Topology-Specific Experts for Molecular Property Prediction1vanilla_1
Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov Decision Processes,ICML,11,"Jun, K. S., Bhargava, A., Nowak, R., & Willett, R.",4.0,Scalable Generalized Linear Bandits: Online Computation and Hashing,2018.0,Advances in Neural Information Processing Systems,522233bda5d1c89fa8c73813cd494f22b26ac738,Scalable Generalized Linear Bandits: Online Computation and Hashing,Neural Information Processing Systems,Neural Information Processing Systems,2017.0,"Kwang-Sung Jun, Aniruddha Bhargava, R. Nowak, R. Willett",4.0,100.0,13.0,39.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,90.0,1.0,Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov Decision Processes11,67.0,67.0,NeurIPS,NeurIPS,vanilla_1,0,Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov Decision Processes11vanilla_1
Self-Correcting Bayesian Optimization through Bayesian Active Learning,NeurIPS,38,"Lizotte, D. J., Wang, T., Bowling, M., & Schuurmans, D.",4.0,Automatic gait optimization with Gaussian process regression,2007.0,Proceedings of the 20th International Conference on Artificial Intelligence,d89e23d3267c75db75e2055951facc2d74f2908b,Automatic Gait Optimization with Gaussian Process Regression,International Joint Conference on Artificial Intelligence,International Joint Conference on Artificial Intelligence,2007.0,"D. Lizotte, Tao Wang, Michael Bowling, Dale Schuurmans",4.0,305.0,15.0,20.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,92.0,1.0,Self-Correcting Bayesian Optimization through Bayesian Active Learning38,60.0,60.0,Proceedings of the 20th International Conference on Artificial Intelligence,International Joint Conference on Artificial Intelligence,vanilla_1,0,Self-Correcting Bayesian Optimization through Bayesian Active Learning38vanilla_1
Federated Learning with Partial Model Personalization,ICML,34,"H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Aguera y Arcas",5.0,Communication-Efficient Learning of Deep Networks from Decentralized Data,2017.0,20th International Conference on Artificial Intelligence and Statistics (AISTATS),d1dbf643447405984eeef098b1b320dee0b3b8a7,Communication-Efficient Learning of Deep Networks from Decentralized Data,International Conference on Artificial Intelligence and Statistics,International Conference on Artificial Intelligence and Statistics,2016.0,"H. B. McMahan, Eider Moore, Daniel Ramage, S. Hampson, B. A. Y. Arcas",5.0,9689.0,2596.0,50.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,94.0,1.0,Federated Learning with Partial Model Personalization34,73.0,73.0,20th International Conference on Artificial Intelligence and Statistics (AISTATS),International Conference on Artificial Intelligence and Statistics,vanilla_1,1,Federated Learning with Partial Model Personalization34vanilla_1
Efficient Graph Field Integrators Meet Point Clouds,ICML,9,"Spielman, D. A., Teng, S. H.",2.0,"Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems",2004.0,Proceedings of the thirty-sixth annual ACM symposium on Theory of computing,407b1ad9d0dbcef919a0c4624b65323cafcb5f11,"Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems",Symposium on the Theory of Computing,Symposium on the Theory of Computing,2003.0,"D. Spielman, S. Teng",2.0,967.0,92.0,33.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,Efficient Graph Field Integrators Meet Point Clouds9,102.0,102.0,Proceedings of the thirty-sixth annual ACM symposium on Theory of computing,Symposium on the Theory of Computing,vanilla_1,1,Efficient Graph Field Integrators Meet Point Clouds9vanilla_1
TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs,AAAI,17,"Leskovec, J., Leskovec, J., & Faloutsos, C.",3.0,"Graphs over time: densification laws, shrinking diameters and possible explanations",2005.0,Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining,788b6f36a2b7cab86a5a29000e8b7cde25b85e73,"Graphs over time: densification laws, shrinking diameters and possible explanations",Knowledge Discovery and Data Mining,Knowledge Discovery and Data Mining,2005.0,"J. Leskovec, J. Kleinberg, C. Faloutsos",3.0,2532.0,205.0,31.0,False,"['Mathematics', 'Computer Science']","[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}, {'category': 'Sociology', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,100.0,1.0,TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs17,83.0,83.0,Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining,Knowledge Discovery and Data Mining,vanilla_1,1,TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs17vanilla_1
Fast Nonlinear Vector Quantile Regression,ICLR,3,"Cuturi, M., & Peyré, G.",2.0,A Smoothed Dual Approach for Variational Wasserstein Problems,2015.0,Siam Journal on Imaging Sciences,1c25d9f677192bfafd3c8722827e452518bf40ed,A Smoothed Dual Approach for Variational Wasserstein Problems,SIAM Journal of Imaging Sciences,SIAM Journal of Imaging Sciences,2015.0,"Marco Cuturi, G. Peyré",2.0,167.0,19.0,52.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,93.0,1.0,Fast Nonlinear Vector Quantile Regression3,61.0,61.0,Siam Journal on Imaging Sciences,SIAM Journal of Imaging Sciences,vanilla_1,1,Fast Nonlinear Vector Quantile Regression3vanilla_1
Interpretability with full complexity by constraining feature information,ICLR,25,"Achille, A., & Soatto, S.",2.0,Emergence of invariance and disentanglement in deep representations,2018.0,The Journal of Machine Learning Research,4d7574c0c4aca70e5811a8e33906f0106d6b76e6,Emergence of Invariance and Disentanglement in Deep Representations,Information Theory and Applications Workshop,Information Theory and Applications Workshop,2017.0,"A. Achille, Stefano Soatto",2.0,407.0,40.0,46.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",0.0,0.0,0.0,100.0,94.0,1.0,Interpretability with full complexity by constraining feature information25,67.0,67.0,JMLR,Information Theory and Applications Workshop,vanilla_1,0,Interpretability with full complexity by constraining feature information25vanilla_1
Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency,NeurIPS,6,"Hawryszkiewycz, A., & Hamilton, J. D.",2.0,Factorization of predictive densities for large scale macroeconomic forecasting,2020.0,International Journal of Forecasting,,,,,,,,,,,,,,0.0,0.0,1.0,,,0.0,Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency6,79.0,,International Journal of Forecasting,,vanilla_1,0,Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency6vanilla_1
Concentration of Data Encoding in Parameterized Quantum Circuits,NeurIPS,11,"M. Schuld, et al.",et al.,Circuit-centric quantum classifiers,2020.0,Physical Review A,804f822f9a6db8f559801f1c618b7d6c766741b4,Circuit-centric quantum classifiers,Physical Review A,,2018.0,"M. Schuld, A. Bocharov, K. Svore, N. Wiebe",4.0,502.0,49.0,52.0,True,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,100.0,1.0,Concentration of Data Encoding in Parameterized Quantum Circuits11,35.0,35.0,Physical Review A,Physical Review A,vanilla_1,1,Concentration of Data Encoding in Parameterized Quantum Circuits11vanilla_1
Artificial Neuronal Ensembles with Learned Context Dependent Gating,ICLR,6,"Goodfellow, I. J., Mirza, M., Xiao, D., Courville, A., Bengio, Y.",5.0,An empirical investigation of catastrophic forgeting in gradient-based neural networks,2013.0,arXiv preprint,0407b605b8f55db72e2545586bfe8e946b691b70,An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks,International Conference on Learning Representations,International Conference on Learning Representations,2013.0,"I. Goodfellow, Mehdi Mirza, Xia Da, Aaron C. Courville, Yoshua Bengio",5.0,1065.0,81.0,19.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]",1.0,1.0,0.0,100.0,83.0,1.0,Artificial Neuronal Ensembles with Learned Context Dependent Gating6,86.0,86.0,arxiv,ICLR,vanilla_1,1,Artificial Neuronal Ensembles with Learned Context Dependent Gating6vanilla_1
